import os
import operator
from typing import Annotated, List, TypedDict, Union, Optional
from dotenv import load_dotenv

# Imports do LangChain/LangGraph
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage

# Imports do seu projeto existente
from models.schemas import PeticaoAIOutput, DadosTecnicos, CorrecaoItem
from services.search import search_jurisprudence
from services.calculations import generate_payment_table

load_dotenv()

# --- 1. DEFINI√á√ÉO DO ESTADO ---
class AgentState(TypedDict):
    input_text: str
    doc_type: str
    client_data: dict 
    system_instruction: Optional[str]
    
    research_results: str 
    calc_results: str
    
    draft: Optional[PeticaoAIOutput]
    review_comments: str
    quality_score: int
    revision_count: int

# CONFIGURA√á√ÉO DO MODELO
llm = ChatOpenAI(model="gpt-4o", temperature=0)

# --- 2. AGENTES (N√ìS DO GRAFO) ---

# üß† ORQUESTRADOR
def orchestrator_node(state: AgentState):
    print("ü§ñ [ORCHESTRATOR] Analisando estado do processo...")
    
    res = state.get("research_results", "")
    if not res or len(str(res).strip()) < 10:
        return {"next": "researcher"}
    
    calc = state.get("calc_results", "")
    if not calc or len(str(calc).strip()) < 5:
        return {"next": "calculator"}
        
    if not state.get("draft"):
        return {"next": "writer"}
        
    score = state.get("quality_score", 0)
    
    # L√≥gica de fluxo: Writer -> Editor -> Reviewer
    # Como n√£o temos uma flag expl√≠cita de "editado", podemos usar o fluxo do grafo.
    # Mas para simplificar a decis√£o aqui:
    # O grafo abaixo for√ßar√°: Writer -> Editor -> Reviewer.
    # O Orquestrador s√≥ decide o loop de repeti√ß√£o.
    
    if score == 0:
        return {"next": "reviewer"}
        
    rev_count = state.get("revision_count", 0)
    if score < 8 and rev_count < 2:
        print(f"   üîÑ Nota baixa ({score}). Solicitando reescrita. Tentativa {rev_count+1}/2")
        return {"next": "writer"}
        
    print("   ‚úÖ Processo conclu√≠do com sucesso.")
    return {"next": "END"}

# üìö PESQUISADOR
async def researcher_node(state: AgentState):
    print("üîé [RESEARCHER] Buscando jurisprud√™ncia...")
    query = f"{state['doc_type']} {state['input_text'][:50]}"
    results = await search_jurisprudence(query)
    formatted_results = "\n".join([f"- {r['title']}: {r['snippet']}" for r in results])
    return {"research_results": formatted_results or "Nenhuma jurisprud√™ncia encontrada."}

# üßÆ CALCULISTA
def calculator_node(state: AgentState):
    print("üí∞ [CALCULATOR] Processando valores...")
    c_data = state.get("client_data", {})
    birth_date = c_data.get("child_birth_date") or "2024-01-01"
    table, total = generate_payment_table(birth_date)
    summary = f"Valor Total da Causa: R$ {total}. Tabela com {len(table)} compet√™ncias."
    return {"calc_results": summary}

# ‚úçÔ∏è ESCRITOR (JUR√çDICO)
def writer_node(state: AgentState):
    print("‚úçÔ∏è [WRITER] Redigindo a peti√ß√£o...")
    
    feedback = state.get("review_comments", "")
    if feedback:
        print(f"   ‚ö†Ô∏è Aplicando corre√ß√µes do Revisor: {feedback}")

    instruction_from_db = state.get("system_instruction")
    base_prompt = instruction_from_db if (instruction_from_db and len(str(instruction_from_db)) > 10) else \
        "Voc√™ √© um Advogado Previdenci√°rio S√™nior. Redija a pe√ßa jur√≠dica final preenchendo o schema JSON rigorosamente."

    data_correction_instruction = """
    TAREFA EXTRA - SANITIZA√á√ÉO DE DADOS:
    Analise o JSON 'client_data' fornecido.
    1. Campos Simples: Corrija 'name', 'address', 'profession' (ex: "lauradora" -> "Lavradora").
    2. Listas: Corrija nomes em 'children', 'evidence_list'.
    Preencha 'dados_cadastrais_corrigidos' APENAS com os campos alterados.
    """

    system_prompt = f"""{base_prompt}
    
    {data_correction_instruction}

    Contexto Jur√≠dico: {{research}}
    Dados Financeiros: {{calcs}}
    Cr√≠ticas Anteriores: {{feedback}}"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "Caso: {input}\nTipo: {doc_type}")
    ])
    
    structured_llm = llm.with_structured_output(PeticaoAIOutput)
    chain = prompt | structured_llm
    
    result = chain.invoke({
        "research": state.get("research_results"),
        "calcs": state.get("calc_results"),
        "feedback": feedback,
        "input": state["input_text"],
        "doc_type": state["doc_type"]
    })
    
    return {
        "draft": result,
        "revision_count": state.get("revision_count", 0) + 1,
        "quality_score": 0,
        "review_comments": "" 
    }

# üìù AGENTE NOVO: EDITOR (GRAM√ÅTICA E ESTILO)
def editor_node(state: AgentState):
    print("E [EDITOR] Revisando gram√°tica e estilo...")
    
    draft = state["draft"]
    
    # Prompt focado puramente na l√≠ngua portuguesa
    system_prompt = """Voc√™ √© um Revisor Gramatical implac√°vel de um escrit√≥rio de advocacia de alto n√≠vel.
    Sua tarefa √© polir o texto jur√≠dico gerado, garantindo:
    1. Concord√¢ncia nominal e verbal perfeita.
    2. Uso correto de crase e pontua√ß√£o.
    3. Substitui√ß√£o de termos repetitivos por sin√¥nimos elegantes.
    4. Clareza e coes√£o textual.
    
    N√ÉO altere os fatos, datas ou valores. Apenas a forma do texto.
    Retorne o MESMO objeto JSON, mas com os campos de texto ('resumo_fatos') aprimorados.
    """
    
    # Criamos um prompt que recebe o objeto Draft e pede o mesmo objeto de volta, mas melhorado
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "Corrija este rascunho: {draft_json}")
    ])
    
    structured_llm = llm.with_structured_output(PeticaoAIOutput)
    chain = prompt | structured_llm
    
    # Passamos o dump do modelo atual para ele reescrever
    improved_draft = chain.invoke({
        "draft_json": draft.model_dump_json()
    })
    
    return {"draft": improved_draft}

# üïµÔ∏è REVISOR (JUR√çDICO)
def reviewer_node(state: AgentState):
    print("‚öñÔ∏è [REVIEWER] Analisando qualidade jur√≠dica...")
    
    draft = state["draft"]
    
    check_prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© um Juiz Federal rigoroso. Analise o resumo dos fatos e provas.
        Se estiver bom, responda apenas 'APROVADO'.
        Se estiver ruim, incompleto ou alucinado, liste os erros resumidamente."""),
        ("human", f"Resumo: {draft.resumo_fatos}\nProvas: {draft.lista_provas}")
    ])
    
    response = llm.invoke(check_prompt.format_messages())
    content = response.content.strip()
    
    if "APROVADO" in content.upper():
        score = 10
        comments = ""
    else:
        score = 5 
        comments = content
        print(f"   ‚ùå Cr√≠tica encontrada: {comments[:50]}...")
        
    return {
        "quality_score": score, 
        "review_comments": comments
    }

# --- 3. MONTAGEM DO GRAFO ---

workflow = StateGraph(AgentState)

workflow.add_node("orchestrator", orchestrator_node)
workflow.add_node("researcher", researcher_node)
workflow.add_node("calculator", calculator_node)
workflow.add_node("writer", writer_node)
workflow.add_node("editor", editor_node)   # <--- NOVO N√ì
workflow.add_node("reviewer", reviewer_node)

workflow.set_entry_point("orchestrator")

def decide_next(state):
    return state["next"]

workflow.add_conditional_edges(
    "orchestrator",
    decide_next,
    {
        "researcher": "researcher",
        "calculator": "calculator",
        "writer": "writer",
        "reviewer": "reviewer", # Nota: O Orchestrator manda pro Reviewer se score == 0...
        "END": END
    }
)

# FLUXO AJUSTADO:
workflow.add_edge("researcher", "orchestrator")
workflow.add_edge("calculator", "orchestrator")

# AQUI EST√Å A MUDAN√áA PRINCIPAL NO FLUXO:
# Writer -> Editor -> Reviewer -> Orchestrator
# Quando o Writer termina, ele manda para o Editor.
# Quando o Editor termina, ele manda para o Reviewer (para ver se a edi√ß√£o n√£o quebrou nada jur√≠dico).
# O Reviewer manda para o Orchestrator (que decide se aprova ou manda reescrever).

workflow.add_edge("writer", "editor")  # Writer passa para Editor
workflow.add_edge("editor", "orchestrator") # Editor volta pro Orquestrador?
# Melhor: Writer -> Editor -> Orchestrator (que vai ver score 0 e mandar pro Reviewer)
# Mas o Orchestrator vai ver 'score=0' e mandar pro 'reviewer'. 
# O problema √©: O writer reseta o score para 0.
# Se Writer -> Editor -> Orchestrator -> Reviewer, funciona.

workflow.add_edge("editor", "orchestrator") # Editor devolve pro Orquestrador
workflow.add_edge("reviewer", "orchestrator")

app_graph = workflow.compile()